import argparse
import hashlib
import io
import json
import math
import os
import random
import sys
from typing import Iterable, Dict, Any, Tuple

try:
    import tiktoken
    enc = tiktoken.get_encoding("cl100k_base")
except Exception:
    enc = None

try:
    from transformers import AutoTokenizer
except Exception:
    AutoTokenizer = None


def stream_jsonl(path: str):
    with (sys.stdin if path == '-' else open(path, 'r', encoding='utf-8')) as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            try:
                yield json.loads(line)
            except json.JSONDecodeError:
                continue


def write_jsonl(path: str, records: Iterable[Dict[str, Any]]):
    with open(path, 'w', encoding='utf-8') as f:
        for rec in records:
            f.write(json.dumps(rec, ensure_ascii=False) + "\n")


def count_tokens(text: str, tokenizer_name_or_path: str | None = None) -> int:
    if enc is not None:
        return len(enc.encode(text))

    if tokenizer_name_or_path and AutoTokenizer is not None:
        tok = AutoTokenizer.from_pretrained(tokenizer_name_or_path, use_fast=True)
        return len(tok.encode(text, truncation=False))

    return int(max(1, math.ceil(len(text.split()) * 1.3)))


def main():
    ap = argparse.ArgumentParser(description='Create deterministic pretrain/retrieval splits and manifests')
    ap.add_argument('--in', dest='inp', required=True, help='Deduped input JSONL (with text, id, url, sha256)')
    ap.add_argument('--out-pretrain', required=True, help='Output pretrain-manifest.jsonl')
    ap.add_argument('--out-retrieval', required=True, help='Output retrieval-manifest.jsonl')
    ap.add_argument('--stats', default='split_stats.yaml', help='Output stats YAML path')
    ap.add_argument('--total-tokens', type=int, required=True, help='Total token budget, e.g. 1000000000')
    ap.add_argument('--pretrain-frac', type=float, required=True, help='Fraction in pretraining, 0..1')
    ap.add_argument('--tokenizer', default=None, help='HF tokenizer name/path (optional)')
    ap.add_argument('--seed', type=int, default=1337, help='Deterministic shuffle seed')
    args = ap.parse_args()

    random.seed(args.seed)

    records = []
    for obj in stream_jsonl(args.inp):
        text = obj.get('text') or ''
        if not text:
            continue
        n_tok = count_tokens(text, args.tokenizer)
        records.append({
            'id': obj.get('id'),
            'url': obj.get('url'),
            'sha256': obj.get('sha256'),
            'n_tokens': n_tok,
            'text': text,
        })

    # Deterministic shuffle by stable key (sha256 + seed jitter)
    def key_fn(r):
        h = int(r['sha256'][:16], 16) if r.get('sha256') else 0
        return (h ^ args.seed)

    records.sort(key=key_fn)

    total_budget = args.total_tokens
    pretrain_budget = int(total_budget * args.pretrain_frac)

    pretrain, retrieval = [], []
    all = 0
    for r in records:
        if all < pretrain_budget:
            pretrain.append(r)
            all += r['n_tokens']
        else:
            retrieval.append(r)

    def manifest(rec_iter):
        for r in rec_iter:
            yield {
                'id': r['id'],
                'url': r['url'],
                'sha256': r['sha256'],
                'n_tokens': r['n_tokens']
            }
    
    os.makedirs(os.path.dirname(args.out_pretrain), exist_ok=True)
    os.makedirs(os.path.dirname(args.out_retrieval), exist_ok=True)

    write_jsonl(args.out_pretrain, manifest(pretrain))
    write_jsonl(args.out_retrieval, manifest(retrieval))

    # Stats
    import yaml
    stats = {
        'seed': args.seed,
        'total_tokens_target': total_budget,
        'pretrain_frac': args.pretrain_frac,
        'pretrain_tokens_actual': sum(r['n_tokens'] for r in pretrain),
        'retrieval_tokens_actual': sum(r['n_tokens'] for r in retrieval),
        'pretrain_docs': len(pretrain),
        'retrieval_docs': len(retrieval),
    }
    with open(args.stats, 'w', encoding='utf-8') as f:
        yaml.safe_dump(stats, f, sort_keys=False)

if __name__ == '__main__':
    main()

