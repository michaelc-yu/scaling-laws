# train_experiment_driver.py
from dataclasses import dataclass
import subprocess
import sys
from typing import List



@dataclass
class LMExperimentConfig:
    """Configuration for a LM training experiment run."""

    # Model parameters
    n_layers: int = 8
    n_heads: int = 8
    d_model: int = 256
    d_ff: int = 512
    vocab_size: int = 50257
    max_seq_len: int = 512

    # Training parameters
    epochs: int = 1
    batch_size: int = 8
    lr: float = 3e-4
    block_size: int = 256
    optimizer: str = "AdamW"
    save_dir: str = "checkpoints"

    # Dataset parameters
    full_data_path: str = "data/processed/wikipedia_deduped.jsonl"
    manifest_path: str = "data/splits/pretrain_manifest.jsonl"
    tokenizer_name: str = "gpt2"
    num_proc = None

    name: str = "tiny"

    def to_command_args(self):
        return [
            f"--n_layers={self.n_layers}",
            f"--n_heads={self.n_heads}",
            f"--d_model={self.d_model}",
            f"--d_ff={self.d_ff}",
            f"--vocab_size={self.vocab_size}",
            f"--max_seq_len={self.max_seq_len}",

            f"--epochs={self.epochs}",
            f"--batch_size={self.batch_size}",
            f"--lr={self.lr}",
            f"--block_size={self.block_size}",
            f"--optimizer={self.optimizer}",
            f"--save_dir={self.save_dir}",

            f"--full_data_path={self.full_data_path}",
            f"--manifest_path={self.manifest_path}",
            f"--tokenizer_name={self.tokenizer_name}",
            f"--num_proc={self.num_proc if self.num_proc is not None else 1}",
        ]


    def description(self) -> str:
        """Return a human-readable description of this config."""
        return f"lr{self.lr}_bs{self.batch_size}_nlayers{self.n_layers}_maxseqlen{self.max_seq_len}"



EXPERIMENTS = [
    # Tiny baseline
    LMExperimentConfig(
        name="tiny_baseline",
        n_layers=4, n_heads=4, d_model=128, d_ff=256,
        max_seq_len=256, epochs=1, batch_size=8, lr=3e-4,
        block_size=256,
        save_dir="checkpoints/tiny_baseline",
    ),
    # Tiny with longer sequence
    LMExperimentConfig(
        name="tiny_longseq",
        n_layers=4, n_heads=4, d_model=128, d_ff=256,
        max_seq_len=512, epochs=1, batch_size=4, lr=3e-4,
        block_size=512,
        save_dir="checkpoints/tiny_longseq",
    ),
    # Small model (toy GPT-2 small-ish)
    LMExperimentConfig(
        name="small_lr_sweep1",
        n_layers=6, n_heads=6, d_model=384, d_ff=1536,
        max_seq_len=512, epochs=2, batch_size=8, lr=1e-4,
        block_size=256,
        save_dir="checkpoints/small_lr1",
    ),
    LMExperimentConfig(
        name="small_lr_sweep2",
        n_layers=6, n_heads=6, d_model=384, d_ff=1536,
        max_seq_len=512, epochs=2, batch_size=8, lr=5e-4,
        block_size=256,
        save_dir="checkpoints/small_lr2",
    ),
]

def run_experiment(cfg: LMExperimentConfig) -> int:
    cmd = [
        "python", "-m", "pretrain.train_model"
    ] + cfg.to_command_args()

    print(f"Running {cfg.description()}")
    try:
        subprocess.run(cmd, check=True)
        print(f"{cfg.description()} completed successfully.")
        return 0
    except subprocess.CalledProcessError as e:
        print(f"{cfg.description()} failed with code {e.returncode}")
        return e.returncode

def main():
    print(f"Starting train experiment driver")
    print(f"Will run {len(EXPERIMENTS)} parameter combinations")
    print("*" * 60)
    failed = []
    for i, cfg in enumerate(EXPERIMENTS, 1):
        print(f"[Experiment {i}/{len(EXPERIMENTS)}] {cfg.description()}")
        return_code = run_experiment(cfg)
        if return_code != 0:
            failed.append(cfg)
    print("\nSummary:")
    print(f"Successful: {len(EXPERIMENTS) - len(failed)}, Failed: {len(failed)}")
    sys.exit(1 if failed else 0)


if __name__ == "__main__":
    main()

